# 5. Sex Differences Analysis

```{r}
library(tidyverse)
library(Metrics)
library(igraph)
library(ComplexHeatmap)
library(ggraph)
library(tidygraph)
library(glmnet)
library(xgboost)
library(SHAPforxgboost)
library(pdp)
library(purrr)
```

## 5.1 Prediction Error by Sex

### 5.1.1 Combine Predictions for Validation Set

To facilitate sex-stratified evaluation of model performance, we first construct a validation dataframe that merges the observed age and sex with the predicted values generated by the Ridge and XGBoost models. This enables direct comparison of prediction accuracy between male and female subgroups.

```{r}
# Filter validation set to matched participants and attach model predictions
valid_preds <- valid %>%
  filter(participant_id %in% valid_merged$participant_id) %>%
  select(participant_id, sex, age) %>%
  mutate(
    Ridge_Pred = ridge_lasso_pca_pred,  # Ridge predicted age
    XGB_Pred   = xgb_pred               # XGBoost predicted age
  )

```

### 5.1.2 Compute RMSE by Sex

To quantify the predictive performance of each model across sexes, we compute the Root Mean Squared Error (RMSE) separately for males and females. This allows us to assess whether either model systematically underperforms for a specific sex group, thereby identifying potential disparities in model accuracy.

```{r}
# Split predictions by sex
male_preds   <- valid_preds %>% filter(sex == "Male")
female_preds <- valid_preds %>% filter(sex == "Female")

# Compute RMSE for each model × sex combination
ridge_rmse_male   <- rmse(male_preds$age, male_preds$Ridge_Pred)
ridge_rmse_female <- rmse(female_preds$age, female_preds$Ridge_Pred)
xgb_rmse_male     <- rmse(male_preds$age, male_preds$XGB_Pred)
xgb_rmse_female   <- rmse(female_preds$age, female_preds$XGB_Pred)

# Summarize in a tibble
tibble(
  Model = rep(c("Ridge", "XGBoost"), each = 2),
  Sex   = rep(c("Male", "Female"), times = 2),
  RMSE  = c(ridge_rmse_male, ridge_rmse_female, xgb_rmse_male, xgb_rmse_female)
)

```

The RMSE results indicate that XGBoost outperforms Ridge regression for both male and female participants, reflecting its greater capacity to model non-linear relationships. Notably, Ridge regression yields slightly higher error for males (RMSE = 6.07) than females (RMSE = 5.72), whereas the pattern is reversed for XGBoost, with male RMSE at 2.56 and female RMSE at 2.88. This reversal suggests that prediction performance disparities across sexes are model-dependent, and motivates further exploration of feature-level differences.

### 5.1.3 Predicted vs Actual Age by Sex

To visualize prediction accuracy and potential bias, we generate scatter plots of predicted versus actual age for both Ridge and XGBoost models, stratified by sex. The 45-degree reference line facilitates assessment of systematic over- or under-prediction patterns across the male and female subgroups.

```{r}
# Scatter plot: Ridge predictions vs actual age, colored by sex
ggplot(valid_preds, aes(x = age, y = Ridge_Pred, color = sex)) +
  geom_point(alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(title = "Ridge: Predicted vs Actual Age by Sex", color = "Sex") +
  theme_minimal()

# Scatter plot: XGBoost predictions vs actual age, colored by sex
ggplot(valid_preds, aes(x = age, y = XGB_Pred, color = sex)) +
  geom_point(alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(title = "XGBoost: Predicted vs Actual Age by Sex", color = "Sex") +
  theme_minimal()

```

Visual comparisons of predicted versus actual age distributions reveal distinct behavioral patterns across models and sex groups. The Ridge model shows a relatively linear relationship but with substantial vertical dispersion, especially at younger ages. Male predictions tend to deviate more severely from the identity line, suggesting higher variance and underfitting in this subgroup. On the other hand, XGBoost predictions cluster more tightly, though they exhibit a clear central tendency: the model systematically underestimates age in older children while slightly overestimating it in younger ones. This “flattening” effect is indicative of regularization-induced bias and may stem from the limited variability captured by tree-based splits. Furthermore, while female predictions under both models remain closer to the identity line on average, their distribution exhibits moderate compression, reflecting potential sex-based model sensitivity.

### 5.1.4 Residual Density and Significance Tests

To further explore sex-based differences in prediction accuracy, we compute residuals (i.e., predicted age minus actual age) for both Ridge and XGBoost models and examine their distribution across sexes. Kernel density plots are used to visualize potential distributional shifts, while both parametric (t-test) and non-parametric (Wilcoxon rank-sum test) statistical tests are conducted to assess whether residuals significantly differ by sex.

```{r}
# Calculate residuals for each model
valid_preds <- valid_preds %>%
  mutate(
    Ridge_Resid = Ridge_Pred - age,
    XGB_Resid   = XGB_Pred   - age
  )

# Density plot of Ridge residuals by sex
ggplot(valid_preds, aes(x = Ridge_Resid, fill = sex)) +
  geom_density(alpha = 0.4) +
  labs(title = "Ridge Residual Density by Sex", x = "Residual") +
  theme_minimal()

# Density plot of XGBoost residuals by sex
ggplot(valid_preds, aes(x = XGB_Resid, fill = sex)) +
  geom_density(alpha = 0.4) +
  labs(title = "XGBoost Residual Density by Sex", x = "Residual") +
  theme_minimal()

# Statistical tests for Ridge residuals by sex
t.test(Ridge_Resid ~ sex, data = valid_preds)        # Parametric
wilcox.test(Ridge_Resid ~ sex, data = valid_preds)   # Non-parametric

```

To further evaluate model performance across sex, we examined the distribution of residuals for Ridge and XGBoost models. The residual density plots reveal a leftward shift in the male distribution compared to females, particularly in the Ridge model, suggesting that male participants' ages were more likely to be underestimated. In contrast, the XGBoost model showed narrower residual spreads and less pronounced differences between groups.

To formally test for group differences in residuals, both Welch’s t-test and the non-parametric Wilcoxon rank-sum test were conducted for the Ridge model. The p-values from these tests (0.0878 and 0.0839, respectively) provide marginal evidence of a difference in prediction error distributions between male and female participants. While not statistically significant at the conventional 5% level, the consistent pattern across tests supports the observation of potential sex-specific prediction bias, particularly under linear modeling assumptions.

### 5.1.5 RMSE by Age Group

To investigate whether model performance varies by age group and sex, the validation set is stratified into four developmental age ranges. Within each subgroup, we calculate the Root Mean Squared Error (RMSE) for Ridge and XGBoost models. The resulting grouped RMSE values are visualized using bar plots, faceted by model type, to facilitate comparison of age-specific prediction accuracy across sexes.

```{r}
# Create age groups and compute RMSE within each group and sex
valid_preds <- valid_preds %>%
  mutate(AgeGroup = cut(age,
                        breaks = c(5, 8, 12, 16, 21),
                        labels = c("5-8", "9-12", "13-16", "17-21")))

age_rmse <- valid_preds %>%
  filter(!is.na(AgeGroup)) %>%   # Exclude NA age groups
  group_by(sex, AgeGroup) %>%
  summarise(
    Ridge_RMSE = sqrt(mean(Ridge_Resid^2)),
    XGB_RMSE   = sqrt(mean(XGB_Resid^2)),
    .groups    = "drop"
  ) %>%
  pivot_longer(cols = starts_with(c("Ridge", "XGB")),
               names_to = "Model",
               values_to = "RMSE")

# Bar plot of RMSE by age group and sex
ggplot(age_rmse, aes(x = AgeGroup, y = RMSE, fill = sex)) +
  geom_col(position = "dodge") +
  facet_wrap(~ Model) +
  labs(title = "RMSE by Age Group & Sex", x = "Age Group", y = "RMSE") +
  theme_minimal()

```

To explore age-dependent variation in model performance, we stratified the validation set into four age groups and computed RMSE for each sex within each stratum. Results show that the Ridge model exhibited the highest prediction error in the youngest group (ages 5–8), with male participants experiencing noticeably larger RMSE than females. For older children and adolescents, Ridge performance became more consistent across sexes, although small differences persisted.

In contrast, the XGBoost model demonstrated lower overall RMSE across all age groups, particularly in the middle ranges (ages 9–16). Notably, sex differences were relatively minor within XGBoost, with a slight female advantage in younger cohorts and a slight male advantage among older adolescents. These findings highlight both age- and sex-specific error patterns, suggesting that nonlinear models may be more robust across heterogeneous subpopulations.

## 5.2 Feature Space Differences via PCA

### 5.2.1 Density Plots of Principal Components by Sex

To examine whether the latent connectome representations differ systematically by sex, we project the validation data onto the first five principal components (PCs) derived from the full training set. We then visualize the distribution of each PC using kernel density plots, stratified by sex. These plots allow for a qualitative assessment of whether structural brain connectivity patterns exhibit sex-specific variation in the low-dimensional feature space.

```{r}
# Extract first 5 PCs and attach sex label
pc_df <- as_tibble(predict(pcs,
                           select(valid, starts_with("V")))[, 1:5]) %>%
  mutate(sex = valid$sex)

# Plot density for each PC
for (i in 1:5) {
  p <- ggplot(pc_df,
              aes_string(x = paste0("PC", i), color = "sex")) +
    geom_density(alpha = 0.5) +
    labs(title = paste0("Density of PC", i, " by Sex")) +
    theme_minimal()
  print(p)
}

```
We examined the distribution of the top five principal components by sex to assess potential structural differences in connectome space. PC1 and PC2 show noticeable shifts between male and female distributions, with males generally exhibiting lower values on PC1. Smaller but consistent differences are also observed in PC3 to PC5, suggesting sex-related variation in the underlying connectivity features.

### 5.2.2 Statistical Tests on Principal Components

To formally assess whether the distributions of the principal components differ significantly by sex, we conduct two-sample t-tests for each of the first five PCs. The resulting p-values are reported to quantify the evidence of sex-based separability in the learned connectome embeddings.

```{r}
# Perform t-test for each PC
pc_tests <- map_df(1:5, function(i) {
  t_result <- t.test(pc_df[[paste0("PC", i)]] ~ pc_df$sex)
  tibble(PC = paste0("PC", i), p.value = t_result$p.value)
})

# Display p-values
print(pc_tests)

```
To formally test for sex-based differences in the connectome-derived feature space, we conducted two-sample t-tests on the top five principal components. The results reveal a statistically significant difference in PC1 (p = 0.0106), indicating that this component captures meaningful variation associated with sex. No significant differences were found in PC2 through PC5 (all p > 0.23), suggesting that the sex effect is primarily concentrated in the leading principal axis.

## 5.3 Feature Importance Comparison (PDP & SHAP)

### 5.3.1 PDP of BMI by Sex (Ridge Regression)

To explore whether the influence of individual predictors differs by sex, we employ partial dependence plots (PDPs) to visualize the marginal effect of BMI on predicted age under sex-specific Ridge regression models. By fitting separate models for males and females, we isolate and compare the shape and slope of the BMI-age relationship, helping to reveal any potential sex-dependent heterogeneity in predictive structure.

```{r}
X_train_male <- train_merged %>% filter(participant_id %in% train$participant_id[train$sex == "Male"]) %>% select(-participant_id)
X_train_female <- train_merged %>% filter(participant_id %in% train$participant_id[train$sex == "Female"]) %>% select(-participant_id)

y_train_male <- train %>% filter(sex == "Male") %>% pull(age)
y_train_female <- train %>% filter(sex == "Female") %>% pull(age)

ridge_male <- cv.glmnet(as.matrix(X_train_male), y_train_male, alpha = 0)
ridge_female <- cv.glmnet(as.matrix(X_train_female), y_train_female, alpha = 0)

ridge_pred_fun <- function(object, newdata) {
  predict(object, newx = as.matrix(newdata), s = "lambda.min")
}

pdp_male <- partial(ridge_male, pred.var = "bmi", train = as.data.frame(X_train_male), grid.resolution = 20, pred.fun = ridge_pred_fun)
pdp_female <- partial(ridge_female, pred.var = "bmi", train = as.data.frame(X_train_female), grid.resolution = 20, pred.fun = ridge_pred_fun)

bind_rows(
  pdp_male %>% mutate(Sex = "Male"),
  pdp_female %>% mutate(Sex = "Female")
) %>%
  ggplot(aes(x = bmi, y = yhat, color = Sex)) +
  geom_line(size = 1) +
  labs(title = "PDP of BMI by Sex (Ridge Regression)", x = "BMI", y = "Predicted Age") +
  theme_minimal()
```
The PDP illustrates the marginal effect of BMI on predicted age across sex-specific Ridge regression models. While both curves exhibit an overall positive relationship, the predicted age for females is consistently higher than that for males at corresponding BMI levels. This suggests that BMI may have a more pronounced association with predicted age in females under the Ridge modeling framework.

### 5.3.2 SHAP Summary for XGBoost by Sex

To complement the linear interpretation offered by Ridge PDPs, we further evaluate feature importance using SHAP (SHapley Additive exPlanations) values from sex-specific XGBoost models. SHAP values decompose each prediction into additive contributions from each feature, enabling a fair and consistent measure of global feature impact. We report and compare the top 10 most influential features for each sex, highlighting any divergence in feature prioritization between groups.

```{r}
# Prepare DMatrix for male/female XGBoost models
dtrain_male   <- xgb.DMatrix(data = as.matrix(X_train_male),   label = y_train_male)
dtrain_female <- xgb.DMatrix(data = as.matrix(X_train_female), label = y_train_female)

# Define XGBoost parameters
params <- list(
  booster           = "gbtree",
  objective         = "reg:squarederror",
  eval_metric       = "rmse",
  eta               = 0.1,
  max_depth         = 4,
  subsample         = 0.8,
  colsample_bytree  = 0.8
)

# Train separate XGBoost models
xgb_male   <- xgb.train(params, dtrain_male,   nrounds = 200)
xgb_female <- xgb.train(params, dtrain_female, nrounds = 200)

# Compute SHAP values for each model
shap_male   <- shap.values(xgb_model = xgb_male,   X_train = as.matrix(X_train_male))
shap_female <- shap.values(xgb_model = xgb_female, X_train = as.matrix(X_train_female))

# Extract top 10 features by mean |SHAP| score
top10_male   <- sort(shap_male$mean_shap_score,   decreasing = TRUE)[1:10]
top10_female <- sort(shap_female$mean_shap_score, decreasing = TRUE)[1:10]

# Combine for plotting
shap_long <- bind_rows(
  tibble(Feature = names(top10_male),   SHAP = top10_male,   Sex = "Male"),
  tibble(Feature = names(top10_female), SHAP = top10_female, Sex = "Female")
)

# Plot SHAP value comparison
ggplot(shap_long, aes(x = reorder(Feature, SHAP), y = SHAP, fill = Sex)) +
  geom_col(position = "dodge") +
  coord_flip() +
  labs(title = "Top 10 SHAP Features by Sex (XGBoost)",
       x = "Feature", y = "Mean |SHAP Value|") +
  theme_minimal()

```
The SHAP summary plot reveals the top predictors of age for each sex under the XGBoost model. BMI consistently emerged as the most influential feature for both males and females, followed by principal components such as PC1 and PC19. While there is general overlap in the top features across sexes, certain components (e.g., PC19, PC11) show sex-specific prominence, suggesting subtle differences in how feature importance contributes to model predictions.

## 5.4 Connectome Differences and Network Visualization

### 5.4.1 Heatmap of Connectivity Differences

To quantify neural connectivity differences between sexes, we compute and contrast the mean connectome vectors for male and female participants. These vectors are reconstructed into symmetric adjacency matrices and differenced to yield a sex-specific connectivity difference matrix. The resulting matrix is visualized as a heatmap, enabling identification of brain regions with elevated or diminished average connectivity across sex.

```{r}
# Extract connectome features for valid participants
valid_feats <- df %>%
  filter(participant_id %in% valid_merged$participant_id) %>%
  select(participant_id, sex, starts_with("V"))

# Compute mean connectivity vector by sex
male_mean_vec   <- valid_feats %>% filter(sex == "Male")   %>% select(starts_with("V")) %>% summarise_all(mean) %>% unlist()
female_mean_vec <- valid_feats %>% filter(sex == "Female") %>% select(starts_with("V")) %>% summarise_all(mean) %>% unlist()

# Recover adjacency matrix dimension
n <- as.integer((sqrt(8 * length(male_mean_vec) + 1) + 1) / 2)

# Build symmetric difference matrix
diff_vec <- male_mean_vec - female_mean_vec
diff_mat <- matrix(0, n, n)
diff_mat[upper.tri(diff_mat)] <- diff_vec
diff_mat <- diff_mat + t(diff_mat) - diag(diag(diff_mat))

# Visualize as heatmap
Heatmap(diff_mat, name = "Male–Female\nConnectivity")

```
The heatmap illustrates the difference in mean connectome connectivity between males and females across all brain region pairs. Warm colors (red) indicate higher average connectivity in males, while cool colors (blue) indicate stronger connectivity in females. The symmetric pattern and hierarchical clustering reveal broad but heterogeneous sex-specific differences in functional brain organization.

### 5.4.2 Subnetwork of Top Differences

To highlight the most salient structural differences, we extract the 50 connectome edges with the largest absolute sex-based discrepancies. We then construct a subgraph consisting of the associated brain regions and visualize this reduced network using a force-directed layout. Edge width and color encode the magnitude of difference, offering an interpretable and compact representation of key structural divergences.

```{r}
# Create full graph from difference matrix
g_full <- graph_from_adjacency_matrix(diff_mat,
                                      mode = "undirected",
                                      weighted = TRUE,
                                      diag = FALSE)
V(g_full)$name <- as.character(1:vcount(g_full))

# Select top 50 edges by absolute weight
edges_df <- igraph::as_data_frame(g_full, what = "edges") %>%
  as_tibble() %>%
  slice_max(abs(weight), n = 50)

# Induce subgraph on nodes involved in top edges
nodes_to_keep <- unique(c(edges_df$from, edges_df$to))
g_sub <- induced_subgraph(g_full, vids = as.integer(nodes_to_keep))
E(g_sub)$weight <- abs(E(g_sub)$weight)

# Plot subnetwork with edge width & color mapped to weight
g_sub %>%
  as_tbl_graph() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_width = weight, edge_color = weight),
                 show.legend = FALSE, alpha = 0.8) +
  scale_edge_color_gradient2(low = "blue", mid = "white", high = "red") +
  geom_node_point(size = 3) +
  geom_node_text(aes(label = name), repel = TRUE, size = 3) +
  theme_graph() +
  labs(title = "Subnet: Top 50 Male–Female Connectivity Differences")

```
We constructed a subnetwork comprising the 50 brain connections with the largest absolute differences in mean connectivity between male and female participants. The resulting graph reveals that connectivity differences are not randomly scattered but instead concentrated around a few hub-like nodes, such as Node 192, 61, and 69. These nodes exhibit disproportionately higher connectivity divergence and may play a central role in sex-specific brain development. Moreover, the asymmetrical and dense structure of this subgraph suggests localized rather than global sex differences in connectome organization. These findings highlight potential regions of interest for future neurobiological investigations into sex-related functional specialization.

### 5.4.3 Barplot of Top 10 Connectivity Differences

For further clarity, we summarize the top 10 brain region pairs with the largest sex-based differences in connectome strength. This barplot provides a ranked view of the most prominent edges contributing to network-level distinctions between male and female participants.

```{r}
# Barplot for the 10 largest absolute connectivity differences
edges_df %>%
  mutate(pair = paste0(from, "–", to)) %>%
  arrange(desc(abs(weight))) %>%
  slice_head(n = 10) %>%
  ggplot(aes(x = reorder(pair, abs(weight)), y = abs(weight))) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "Top 10 Brain Connections with Largest Sex Differences",
       x = "Brain Region Pair", y = "Absolute Difference") +
  theme_minimal()

```
The bar chart summarizes the top 10 brain region pairs exhibiting the largest absolute differences in mean connectivity between male and female participants. Notably, the connection between regions 77 and 81 shows the most pronounced sex difference, with an absolute divergence exceeding 0.15. Several other region pairs involving node 61 (e.g., 61–76, 61–78, 61–69) also appear prominently, reinforcing its potential role as a sex-sensitive hub. These findings complement the subnetwork visualization and suggest that specific neural circuits, rather than diffuse patterns, account for most of the observed sex-based connectivity disparities. Such localized differences may be critical for understanding functional specialization in brain development across sexes.

## 5.5 Summary of Sex Differences Findings

Our analysis revealed several notable sex differences in both predictive performance and brain network characteristics. First, while Ridge regression exhibited slightly better RMSE in females, XGBoost showed superior performance in males, suggesting potential disparities in model fit or neurodevelopmental patterns across sexes. Residual distribution plots and statistical tests further indicated that the Ridge model tended to systematically underpredict female ages relative to males.

Principal component analysis (PCA) on connectome features showed a statistically significant difference in the first component (PC1) between sexes, indicating that overall connectome structure partially encodes sex-specific variation. Partial dependence plots (PDP) and SHAP analysis also revealed divergent patterns of feature importance; for example, BMI had a stronger marginal effect on age prediction in males than in females, and different metadata features ranked highest in SHAP importance across sexes.

Finally, comparison of average connectome vectors identified brain regions with the largest sex-specific connectivity differences. A subnetwork of the top 50 connections demonstrated concentrated divergence around specific hubs, such as Node 192 and Node 61, suggesting localized rather than diffuse sex-based structural differences.

Together, these findings support the hypothesis that male and female brain networks follow distinct developmental trajectories during adolescence. This underscores the importance of sex-specific modeling in neurodevelopmental research and highlights potential regions of interest for future investigation into brain-based biomarkers of psychiatric risk.